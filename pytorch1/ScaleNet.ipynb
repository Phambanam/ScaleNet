{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bae88ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import math\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from heper_dataset import get_dataloaders_cifar10,UnNormalize\n",
    "import matplotlib.pyplot as plt\n",
    "from helper_evaluation import set_all_seeds, set_deterministic, compute_confusion_matrix\n",
    "from helper_train import train_model\n",
    "from helper_plotting import plot_training_loss, plot_accuracy, show_examples, plot_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d52a60ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 123\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 50\n",
    "DEVICE = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8986d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds(RANDOM_SEED)\n",
    "#set_deterministic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "552ff4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Image batch dimensions: torch.Size([256, 3, 110, 110])\n",
      "Image label dimensions: torch.Size([256])\n",
      "Class labels of 10 examples: tensor([4, 7, 4, 6, 2, 6, 9, 7, 3, 0])\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### CIFAR-10 DATASET\n",
    "##########################\n",
    "\n",
    "\n",
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((120, 120)),\n",
    "    torchvision.transforms.RandomCrop((110, 110)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                      ])\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((120, 120)),        \n",
    "    torchvision.transforms.CenterCrop((110, 110)),            \n",
    "    torchvision.transforms.ToTensor(),                \n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders_cifar10(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_fraction=0.1,\n",
    "    train_transforms=train_transforms,\n",
    "    test_transforms=test_transforms,\n",
    "    num_workers=2)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    print('Class labels of 10 examples:', labels[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43d25b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SABlock(nn.Module):\n",
    "    layer_idx = -1\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, bias=False, downsample=False, structure=[]):\n",
    "        super(SABlock, self).__init__()\n",
    "        if SABlock.layer_idx < len(structure):\n",
    "            SABlock.layer_idx += 1\n",
    "        channels = structure[SABlock.layer_idx][:-1]\n",
    "        side = structure[SABlock.layer_idx][-1]\n",
    "        \n",
    "        self.scales = [None, 2, 4, 7]\n",
    "        \n",
    "        self.stride = stride\n",
    "        \n",
    "\n",
    "        self.downsample = None if downsample == False else \\\n",
    "                          nn.Sequential(nn.Conv2d(inplanes, planes * SABlock.expansion, kernel_size=1, stride=1, bias=bias),\n",
    "                                        nn.BatchNorm2d(planes * SABlock.expansion))\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=bias)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        # kernel size == 1 if featuremap size == 1\n",
    "        self.conv2 = nn.ModuleList([nn.Conv2d(planes, channels[i], kernel_size=3 if side / 2**i > 1 else 1, stride=1, padding=1 if side / 2**i > 1 else 0, bias=bias) if channels[i] > 0 else \\\n",
    "                                    None for i in range(len(self.scales))])\n",
    "        self.bn2 = nn.ModuleList([nn.BatchNorm2d(channels[i]) if channels[i] > 0 else \\\n",
    "                                  None for i in range(len(self.scales))])\n",
    "\n",
    "        self.conv3 = nn.Conv2d(sum(channels), planes * SABlock.expansion, kernel_size=1, bias=bias)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * SABlock.expansion)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(x, self.stride, self.stride) if self.stride > 1 else x\n",
    "    \n",
    "        residual = self.downsample(x) if self.downsample != None else x\n",
    "\n",
    "        out1 = self.conv1(x)\n",
    "        out1 = F.relu(self.bn1(out1))\n",
    "      \n",
    "        out2_list = []\n",
    "        size = [out1.size(2), out1.size(3)]\n",
    "        for i in range(len(self.scales)):\n",
    "            out2_i = out1 # copy\n",
    "            if self.scales[i] != None:\n",
    "                out2_i = F.max_pool2d(out2_i, self.scales[i], self.scales[i])\n",
    "            if self.conv2[i] != None:\n",
    "                out2_i = self.conv2[i](out2_i)\n",
    "            if self.scales[i] != None:\n",
    "                # nearest mode is not suitable for upsampling on non-integer multiples \n",
    "                mode = 'nearest' if size[0] % out2_i.shape[2] == 0 and size[1] % out2_i.shape[3] == 0 else 'bilinear'\n",
    "                out2_i = F.interpolate(out2_i, size=size, mode=mode)\n",
    "            if self.bn2[i] != None:\n",
    "                out2_i = self.bn2[i](out2_i)\n",
    "                out2_list.append(out2_i)\n",
    "        out2 = torch.cat(out2_list, 1)\n",
    "        out2 = F.relu(out2)\n",
    "\n",
    "        out3 = self.conv3(out2)\n",
    "        out3 = self.bn3(out3)\n",
    "        out3 += residual\n",
    "        out3 = F.relu(out3)\n",
    "\n",
    "        return out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6e85ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, structure, num_classes=1000):\n",
    "        super(ScaleNet, self).__init__()\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.structure = structure\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=1)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=1)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            annels = structure[SABlock.layer_idx][:-1]\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = True if stride != 1 or self.inplanes != planes * block.expansion else False\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample=downsample, structure=self.structure))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, downsample=False, structure=self.structure))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = F.max_pool2d(x, 3, 2, 1)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66c9c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scalenet50(structure_path, ckpt=None, **kwargs):\n",
    "    layer = [3, 4, 6, 3]\n",
    "    structure = json.loads(open(structure_path).read())\n",
    "    model = ScaleNet(SABlock, layer, structure, **kwargs)\n",
    "\n",
    "    # pretrained\n",
    "    if ckpt != None:\n",
    "        state_dict = torch.load(ckpt, map_location='cpu')\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5abd0088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalenet101(structure_path, ckpt=None, **kwargs):\n",
    "    layer = [3, 4, 23, 3]\n",
    "    structure = json.loads(open(structure_path).read())\n",
    "    model = ScaleNet(SABlock, layer, structure, **kwargs)\n",
    "\n",
    "    # pretrained\n",
    "    if ckpt != None:\n",
    "        state_dict = torch.load(ckpt, map_location='cpu')\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e301f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalenet152(structure_path, ckpt=None, **kwargs):\n",
    "    layer = [3, 8, 36, 3]\n",
    "    structure = json.loads(open(structure_path).read())\n",
    "    model = ScaleNet(SABlock, layer, structure, **kwargs)\n",
    "\n",
    "    # pretrained\n",
    "    if ckpt != None:\n",
    "        state_dict = torch.load(ckpt, map_location='cpu')\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b3b151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51e41c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_all_preds(model, loader):\n",
    "    all_preds = torch.tensor([])\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "\n",
    "        preds = model(images)\n",
    "        all_preds = torch.cat(\n",
    "            (all_preds, preds)\n",
    "            ,dim=0\n",
    "        )\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c2c676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = scalenet50(structure_path='../structures/scalenet50.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de31eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phamnam/miniconda3/envs/d2l/lib/python3.8/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       factor=0.1,\n",
    "                                                       mode='max',\n",
    "                                                       verbose=True)\n",
    "\n",
    "minibatch_loss_list, train_acc_list, valid_acc_list = train_model(\n",
    "    model=model,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    test_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    scheduler=scheduler,\n",
    "    scheduler_on='valid_acc',\n",
    "    logging_interval=100)\n",
    "\n",
    "plot_training_loss(minibatch_loss_list=minibatch_loss_list,\n",
    "                   num_epochs=NUM_EPOCHS,\n",
    "                   iter_per_epoch=len(train_loader),\n",
    "                   results_dir=None,\n",
    "                   averaging_iterations=200)\n",
    "plt.show()\n",
    "\n",
    "plot_accuracy(train_acc_list=train_acc_list,\n",
    "              valid_acc_list=valid_acc_list,\n",
    "              results_dir=None)\n",
    "plt.ylim([60, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759c75cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
